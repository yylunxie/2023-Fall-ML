{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework Set 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1(Naive Bayes)\n",
    "\n",
    "P(Purchase) = 9/14\n",
    "P(not Purchase) = 5/14\n",
    "\n",
    "P(Purchase | Age <= 30, Income = medium, Student = yes, Credit rating = Fair) = <br>\n",
    "    P(Purchase) P(Age <= 30 | Purchase) P(Income = medium | Purchase) P(Student = yes | Purchase) P(Credit rating = Fair | Purchase) = <br>\n",
    "    **9/14 * 2/9 * 4/9 * 6/9 * 6/9 = 0.0282186949**<br>\n",
    "\n",
    "P(not Purchase | Age <= 30, Income = medium, Student = yes, Credit rating = Fair) = <br>\n",
    "    P(not Purchase) P(Age <= 30 | not Purchase) P(Income = medium | not Purchase) P(Student = yes | not Purchase) P(Credit rating = Fair | not Purchase) = <br>\n",
    "    **5/14 * 3/5 * 2/5 * 1/5 * 2/5 = 0.0068571429** <br>\n",
    "\n",
    "P(Purchase) = **0.0282186949/(0.0068571429 + 0.0282186949) = 0.804505228382599**<br>\n",
    "P(not Purchase) = **0.0068571429/(0.0068571429 + 0.0282186949) = 0.19549477161740095**<br>\n",
    "\n",
    "\n",
    "Since P(Purchase) > P(not Purchase), <br>\n",
    "**the person will but a computer.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2 (k-nearest neighbor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.ExitStack at 0x20250961490>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ioff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_distance(x, y):\n",
    "    distance = np.sqrt(((x[0] - y[0])**2)*0.5 + (x[1] - y[1])**2)\n",
    "    return distance\n",
    "    \n",
    "\n",
    "def find_line_equation(point1, point2):\n",
    "    x1, y1 = point1\n",
    "    x2, y2 = point2\n",
    "    \n",
    "    # Calculate the slope of the line between the two points\n",
    "    slope = (y2 - y1) / (x2 - x1)\n",
    "    \n",
    "    # Calculate the y-intercept of the line\n",
    "    y_intercept = y1 - slope * x1\n",
    "    \n",
    "    # Return the equation of the line in the form y = mx + b\n",
    "    return slope, y_intercept\n",
    "\n",
    "\n",
    "\n",
    "def find_vertical_line_equation(point1, point2):\n",
    "    x1, y1 = point1\n",
    "    x2, y2 = point2\n",
    "    xm, ym = (point1 + point2)/2\n",
    "    \n",
    "    # Calculate the slope of the line between the two points\n",
    "    slope = (y2 - y1) / (x2 - x1)\n",
    "    \n",
    "    # Calculate the slope of the perpendicular line\n",
    "    perpendicular_slope = -1 / slope\n",
    "    \n",
    "    # Calculate the y-intercept of the perpendicular line\n",
    "    # We can use either point1 or point2 to calculate the y-intercept\n",
    "    # Let's use point1\n",
    "    y_intercept = ym - perpendicular_slope * xm\n",
    "    print(f\"y = {perpendicular_slope}x + {y_intercept}\")\n",
    "    # Return the equation of the perpendicular line in the form y = mx + b\n",
    "    return perpendicular_slope, y_intercept\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = -1.0x + 4.0\n",
      "y = 1.0x + -1.0\n",
      "y = -3.0x + 9.0\n",
      "y = -1.0x + 4.0\n",
      "y = -3.0x + 9.0\n"
     ]
    }
   ],
   "source": [
    "x_test = np.linspace(0, 5, 3001)\n",
    "\n",
    "pts = np.array([[1, 1], [3, 3], [4, 2]])\n",
    "y_test = []\n",
    "for i in range(3):\n",
    "    m, b = find_vertical_line_equation(pts[i], pts[(i+1)%3])\n",
    "    y = m*x_test + b\n",
    "    y_test.append(y)\n",
    "# print(y_test)\n",
    "\n",
    "m1, b1 = find_vertical_line_equation(pts[0], pts[1])\n",
    "m2, b2 = find_vertical_line_equation(pts[0], pts[2])\n",
    "x_int = (b1 - b2)/(m2 - m1)\n",
    "y_int = m1*x_int + b1\n",
    "\n",
    "\n",
    "\n",
    "# find_decision_boundary(intercept_12[0], intercept_12[1])     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training data\n",
    "X_train = np.array([[1, 1], [3, 3], [4, 2]])\n",
    "y_train = np.array([1, 2, 3])\n",
    "\n",
    "# Create the 1-nearest neighbor classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Define the test data\n",
    "X_test = np.array([[2, 2]])\n",
    "\n",
    "# Predict the class labels for the test data\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Plot the decision boundary\n",
    "h = 0.02  # step size in the mesh\n",
    "x_min, x_max = X_train[:, 0].min() - 1, X_train[:, 0].max() + 1\n",
    "y_min, y_max = X_train[:, 1].min() - 1, X_train[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "Z = knn.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure(figsize=(5, 4))\n",
    "plt.contourf(xx, yy, Z, alpha=0.8)\n",
    "\n",
    "# Plot the training points\n",
    "plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=plt.cm.Set1, edgecolor='k')\n",
    "plt.text(2.7, -3 * 2.7 + 9, 'y = -3.0x + 9.0', ha='left', va='bottom')\n",
    "plt.text(3.3, 1.0 * 3.3 + -1, 'y = 1.0x + -1.0', ha='left', va='bottom')\n",
    "plt.text(1, -1.0 * 1 + 4, 'y = -1.0x + 4.0', ha='left', va='bottom')\n",
    "plt.xlabel(r'$x_1$', fontsize=14)\n",
    "plt.ylabel(r'$x_2$', fontsize=14)\n",
    "plt.title('1-Nearest Neighbor Decision Boundary')\n",
    "for i, label in enumerate(y_train):\n",
    "    plt.text(X_train[i, 0], X_train[i, 1], str(label), ha='left', va='bottom')\n",
    "plt.axis([x_min, x_max, y_min, y_max])\n",
    "plt.tight_layout()\n",
    "plt.savefig('decision_boundary.png', dpi=300)\n",
    "plt.close()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![asd](decision_boundary.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Custom distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_line(type):\n",
    "    pts = np.array([[1, 1], [3, 3], [4, 2]])\n",
    "    if type == 0:\n",
    "        pt1 = pts[0]\n",
    "        pt2 = pts[1]\n",
    "    elif type == 1:\n",
    "        pt1 = pts[0]\n",
    "        pt2 = pts[2]\n",
    "    elif type == 2:\n",
    "        pt1 = pts[1]\n",
    "        pt2 = pts[2]\n",
    "    \n",
    "    xm = (pt1[0] + pt2[0])/2\n",
    "    ym = (pt1[1] + pt2[1])/2\n",
    "    x = 0\n",
    "    a = (np.square(- pt1[0]) - np.square( - pt2[0]))*0.5\n",
    "    y = (a/(pt1[1] - pt2[1]) + pt1[1] + pt2[1])*0.5\n",
    "    \n",
    "    m, b = find_line_equation((x, y), (xm, ym))\n",
    "    print(f\"y = {m}x + {b}\")\n",
    "    return m, b\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = -0.5x + 3.0\n",
      "y = -1.5x + 5.25\n",
      "y = 0.5x + 0.75\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x_test = np.linspace(0, 5, 3001)\n",
    "\n",
    "pts = np.array([[1, 1], [3, 3], [4, 2]])\n",
    "\n",
    "y_test_2 = []\n",
    "for i in range(3):\n",
    "    m, b = custom_line(i)\n",
    "    y = m*x_test + b\n",
    "    y_test_2.append(y)\n",
    "# print(y_test_2)\n",
    "\n",
    "# Define the training data\n",
    "X_train = np.array([[1, 1], [3, 3], [4, 2]])\n",
    "y_train = np.array([1, 2, 3])\n",
    "\n",
    "# Create the 1-nearest neighbor classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=1, metric=custom_distance)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Define the test data\n",
    "X_test = np.array([[2, 2]])\n",
    "\n",
    "# Predict the class labels for the test data\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Plot the decision boundary\n",
    "h = 0.02  # step size in the mesh\n",
    "x_min, x_max = X_train[:, 0].min() - 1, X_train[:, 0].max() + 1\n",
    "y_min, y_max = X_train[:, 1].min() - 1, X_train[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "Z = knn.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure(figsize=(5, 4))\n",
    "plt.contourf(xx, yy, Z, alpha=0.8)\n",
    "\n",
    "# Plot the training points\n",
    "plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=plt.cm.Set1, edgecolor='k')\n",
    "# plt.plot(x_test, y_test_2[0], 'r')\n",
    "plt.text(1, -0.5 * 1 + 3, 'y = -0.5x + 3.0', ha='left', va='bottom')\n",
    "plt.text(2.8, -1.5 * 2.8 + 5.25, 'y = -1.5x + 5.25', ha='left', va='bottom')\n",
    "plt.text(3.5, 0.5 * 3.5 + 0.75, 'y = 0.5x + 0.75', ha='left', va='bottom')\n",
    "plt.xlabel(r'$x_1$', fontsize=14)\n",
    "plt.ylabel(r'$x_2$', fontsize=14)\n",
    "plt.title('1-Nearest Neighbor Decision Boundary')\n",
    "for i, label in enumerate(y_train):\n",
    "    plt.text(X_train[i, 0], X_train[i, 1], str(label), ha='left', va='bottom')\n",
    "plt.axis([x_min, x_max, y_min, y_max])\n",
    "plt.tight_layout()\n",
    "plt.savefig('decision_boundary_custom.png', dpi=300)\n",
    "plt.close()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![asdasd](decision_boundary_custom.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3\n",
    "### (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.RdPu):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        #print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    #print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    \n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    return cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.loadtxt('10HW3_train.txt', dtype = int)\n",
    "val = np.loadtxt('10HW3_validate.txt', dtype = int)\n",
    "test = np.loadtxt('10HW3_test.txt', dtype = int)\n",
    "train_x = train[:,0:784]\n",
    "train_y = train[:,784]\n",
    "val_x = val[:,0:784]\n",
    "val_y = val[:,784]\n",
    "test_x = test[:,0:784]\n",
    "test_y = test[:,784]\n",
    "k_values = [1, 3, 5, 11, 16, 21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_err = []\n",
    "test_err = []\n",
    "val_err = []\n",
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(train_x,train_y)\n",
    "    pred_train = knn.predict(train_x)\n",
    "    pred_test = knn.predict(test_x)\n",
    "    pred_val = knn.predict(val_x)\n",
    "    \n",
    "    err_train = ((pred_train-train_y) != 0)\n",
    "    train_err.append(round(np.sum(err_train)/1000, 3))\n",
    "    err_test = ((pred_test-test_y) != 0)\n",
    "    test_err.append(round(np.sum(err_test)/300, 3))\n",
    "    err_val = ((pred_val-val_y) != 0)\n",
    "    val_err.append(round(np.sum(err_val)/300, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Training error for k = [1, 3, 5, 11, 16, 21] is\\n', train_err)\n",
    "# print('Test error for k = [1, 3, 5, 11, 16, 21] is\\n', test_err)\n",
    "# print('Validation error for k = [1, 3, 5, 11, 16, 21] is\\n', val_err)\n",
    "# print('\\n')\n",
    "# print('The best k for validation data is', k_values[np.argmin(val_err)], 'and validation error is', np.min(val_err))\n",
    "# print('The best k for test data is', k_values[np.argmin(test_err)], 'and test error is', np.min(test_err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer\n",
    "The error values are:<br>\n",
    "|     k     |     Training   Error    |     Validation   Error    |\n",
    "|-----------|-------------------------|---------------------------|\n",
    "|     1     |     0.0                 |     0.127                 |\n",
    "|     3     |     0.068               |     0.143                 |\n",
    "|     5     |     0.084               |     0.13                  |\n",
    "|     11    |     0.118               |     0.173                 |\n",
    "|     16    |     0.139               |     0.197                 |\n",
    "|     21    |     0.155               |     0.203                 |\n",
    "\n",
    "**The best k for validation data is 1 and validation error is 0.127** <br>\n",
    "**The best k for test data is 5 and test error is 0.083**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(train_x,train_y)\n",
    "pre_train = knn.predict(train_x)\n",
    "pre_test = knn.predict(test_x)\n",
    "pre_val = knn.predict(val_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "target_names = ['0','1','2','3','4','5','6','7','8','9']\n",
    "cnf_matrix = confusion_matrix(test_y, pre_test)\n",
    "normal_cm = plot_confusion_matrix(cnf_matrix, classes=target_names,normalize=True,\n",
    "                    title='Confusion matrix of k=3')\n",
    "\n",
    "plt.savefig('confusion_matrix.png', dpi=100)\n",
    "plt.close()\n",
    "# plt.show()\n",
    "# print('The easiest to classify is', target_names[np.argmax(np.diagonal(normal_cm))])\n",
    "# print('The hardest to classify is', target_names[np.argmin(np.diagonal(normal_cm))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer\n",
    "**The easiest to classify is 1**<br>\n",
    "**The hardest to classify is 3**<br>\n",
    "![pic](confusion_matrix.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 0\n",
    "plt.figure(figsize=(10,15))\n",
    "for i in range(len(test_y)):\n",
    "    if g < 10:\n",
    "        if test_y[i] != pred_test[i]:\n",
    "            plt.subplot(5,5,(g+1))\n",
    "            plt.title('True label = ' + str(test_y[i])+ '\\n' + 'Predict label = ' + str(pred_test[i]))\n",
    "            plt.imshow(np.reshape(test_x[i,:], (28, 28)), cmap = 'gray')\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "            g+=1\n",
    "    else:\n",
    "        break\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('misclassified.png', dpi=300)\n",
    "plt.close()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer\n",
    "\n",
    "**One image from class 2 was classified as class 8.**<br>\n",
    "![miclass](pic1.png) <br>\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML2-wheWIX6u",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
